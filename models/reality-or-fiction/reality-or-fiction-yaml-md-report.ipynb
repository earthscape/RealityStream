{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Loading Dataset into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
       "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/jobs/fake_job_postings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title            location department  \\\n",
       "0                           Marketing Intern    US, NY, New York  Marketing   \n",
       "1  Customer Service - Cloud Video Production      NZ, , Auckland    Success   \n",
       "2    Commissioning Machinery Assistant (CMA)       US, IA, Wever        NaN   \n",
       "3          Account Executive - Washington DC  US, DC, Washington      Sales   \n",
       "4                        Bill Review Manager  US, FL, Fort Worth        NaN   \n",
       "\n",
       "                                     company_profile  \\\n",
       "0  We're Food52, and we've created a groundbreaki...   \n",
       "1  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2  Valor Services provides Workforce Solutions th...   \n",
       "3  Our passion for improving quality of life thro...   \n",
       "4  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits required_experience  \\\n",
       "0                                                NaN          Internship   \n",
       "1  What you will get from usThrough being part of...      Not Applicable   \n",
       "2                                                NaN                 NaN   \n",
       "3  Our culture is anything but corporate—we have ...    Mid-Senior level   \n",
       "4                              Full Benefits Offered    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Unnecessary columns\n",
    "columns = ['job_id','telecommuting','has_company_logo','has_questions','salary_range','employment_type']\n",
    "for col in columns:\n",
    "    del df[col]\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling NaN values with Blank space\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Creating Target and Text Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_fraud_df(df):\n",
    "\n",
    "    # replacing Na values with nothing as a string\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "    # creating a new column named \"text\"\n",
    "    # which is concatination of \"title\", \"company_profile\", \"description\", \"requirements\", benifits\n",
    "    # ' ' space between two concatinations\n",
    "    df['text'] = df['title'] + ' ' + df['company_profile'] + ' '+ df['description'] + df['requirements'] + ' ' + df['benefits'] \n",
    "\n",
    "\n",
    "    for col in df.columns:\n",
    "        # remove all columns except \"text\" and Fradulent\n",
    "        if col not in ['text','fraudulent']:\n",
    "            del df[col]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Marketing Intern We're Food52, and we've creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Customer Service - Cloud Video Production 90 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA) Valor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Account Executive - Washington DC Our passion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Bill Review Manager SpotSource Solutions LLC i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraudulent                                               text\n",
       "0           0  Marketing Intern We're Food52, and we've creat...\n",
       "1           0  Customer Service - Cloud Video Production 90 S...\n",
       "2           0  Commissioning Machinery Assistant (CMA) Valor ...\n",
       "3           0  Account Executive - Washington DC Our passion ...\n",
       "4           0  Bill Review Manager SpotSource Solutions LLC i..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = text_fraud_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Lemmatization, Stopword and Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load spacy nlp model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"]) \n",
    "\n",
    "# Text Preprocessing with varoius combination\n",
    "def spacy_process(text):\n",
    "  # Converts to lowercase\n",
    "  text = text.strip().lower()\n",
    "\n",
    "  # passing text to spacy's nlp object\n",
    "  doc = nlp(text)\n",
    "    \n",
    "  # Lemmatization\n",
    "  lemma_list = []\n",
    "  for token in doc:\n",
    "    lemma_list.append(token.lemma_)\n",
    "  \n",
    "  # Filter the stopword\n",
    "  filtered_sentence =[] \n",
    "  for word in lemma_list:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    if lexeme.is_stop == False:\n",
    "      filtered_sentence.append(word)\n",
    "    \n",
    "  # Remove punctuation\n",
    "  punctuations=\"?:!.,;$\\'-_\"\n",
    "  for word in filtered_sentence:\n",
    "    if word in punctuations:\n",
    "      filtered_sentence.remove(word)\n",
    "\n",
    "  return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>marketing intern food52 create groundbreaking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>customer service cloud video production 90 sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>commission machinery assistant ( cma ) valor s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>account executive washington dc passion improv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>bill review manager spotsource solution llc gl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraudulent                                               text\n",
       "0           0  marketing intern food52 create groundbreaking ...\n",
       "1           0  customer service cloud video production 90 sec...\n",
       "2           0  commission machinery assistant ( cma ) valor s...\n",
       "3           0  account executive washington dc passion improv...\n",
       "4           0  bill review manager spotsource solution llc gl..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,\"text\"] = df.loc[:,\"text\"].apply(spacy_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate local clean csv \n",
    "df.to_csv('../input/jobs/clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare target csv\n",
    "df = pd.read_csv('../input/jobs/clean_df.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Buliding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt, argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "import markdown\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframe with word-vectors in TF-IDF form and Target values\n",
    "\n",
    "def final_df(df, is_train, vectorizer, column):\n",
    "\n",
    "    # TF-IDF form\n",
    "    if is_train:\n",
    "        x = vectorizer.fit_transform(df.loc[:,column])\n",
    "    else:\n",
    "        x = vectorizer.transform(df.loc[:,column])\n",
    "\n",
    "    # TF-IDF form to Dataframe\n",
    "    temp = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Droping the text column\n",
    "    df.drop(df.loc[:,column].name, axis = 1, inplace=True)\n",
    "\n",
    "    # Returning TF-IDF form with target\n",
    "    return pd.concat([temp, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with various combination and returns y_test and y_pred\n",
    "\n",
    "def train_model(df, input, target, test_size, over_sample, vectorizer, model):\n",
    "\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    print(\"Splitted Data into X and Y.\")\n",
    "\n",
    "    X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print(\"Splitted Data into Train and Test.\")\n",
    "    \n",
    "    # Training Preprocessing\n",
    "    X_train = final_df(X_train, True, vectorizer, input)\n",
    "    X_train.dropna(inplace=True)\n",
    "    print(\"Vectorized Training Data.\")\n",
    "\n",
    "    if over_sample:\n",
    "        sm = SMOTE(random_state = 2)\n",
    "        X_train, Y_train = sm.fit_resample(X_train, Y_train.ravel())\n",
    "        print(\"Oversampling Done for Training Data.\")\n",
    "\n",
    "    # Testing Preprocessing\n",
    "\n",
    "    x_test_init = x_test.copy()\n",
    "    #x_test_init.dropna(inplace=True)\n",
    "    \n",
    "    x_test = final_df(x_test, False, vectorizer, input)\n",
    "    x_test.dropna(inplace=True)\n",
    "    print(\"Vectorized Testing Data.\")\n",
    "\n",
    "    # fitting the model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    print(\"Model Fitted Successfully.\")\n",
    "\n",
    "    # calculating y_pred\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_prob = model.predict_proba(x_test)\n",
    "    roc_auc = round(roc_auc_score(y_test, y_pred_prob[:, 1]), 2)\n",
    "\n",
    "    print(f\"\\n\\033[1mROC-AUC Score\\033[0m \\t\\t: {roc_auc*100} %\")\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = sqrt(tpr * (1-fpr))\n",
    "    \n",
    "    # locate the index of the largest g-mean\n",
    "    ix = argmax(gmeans)\n",
    "    print('\\033[1mBest Threshold\\033[0m \\t\\t: %.3f \\n\\033[1mG-Mean\\033[0m \\t\\t\\t: %.3f' % (thresholds[ix], gmeans[ix]))\n",
    "    best_threshold_num = round(thresholds[ix], 3)\n",
    "    gmeans_num = round(gmeans[ix], 3)\n",
    "\n",
    "    y_pred = (y_pred > thresholds[ix])\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracy_num = f\"{accuracy * 100:.1f}\"\n",
    "    \n",
    "    print(\"\\033[1mModel Accuracy\\033[0m \\t\\t:\", round(accuracy*100,2), \"%\")\n",
    "\n",
    "    print(\"\\033[1m\\nClassification Report:\\033[0m\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model, x_test_init, y_test, y_pred, gmeans_num, accuracy_num, roc_auc, best_threshold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_generator(report, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num):\n",
    "    #transfrom report from dictionary to df\n",
    "    df_report = pd.DataFrame.from_dict(report).transpose()\n",
    "\n",
    "    #adjust data display format for md and yaml\n",
    "    df_report['support'] = df_report['support'].astype(int)\n",
    "    df_report.iloc[:, 0:3] = df_report.iloc[:, 0:3].round(2)\n",
    "    df_report.iloc[2,0] = \" \"\n",
    "    df_report.iloc[2,1] = \" \"\n",
    "    df_report.iloc[2,3] = df_report.iloc[3,3]\n",
    "\n",
    "    #edit roc_auc format\n",
    "    roc_auc = roc_auc *100\n",
    "    \n",
    "    #covert numpy float to python float for yaml display\n",
    "    roc_auc = roc_auc.item()\n",
    "    best_threshold_num = best_threshold_num.item() \n",
    "    gmeans_num = gmeans_num.item() \n",
    "\n",
    "    #markdown file content\n",
    "    markdown_content = f\"\"\"\n",
    "## {model_fullname} Accuracy\n",
    "\n",
    "**ROC-AUC Score:** {roc_auc}% &nbsp;&nbsp; **Best Threshold:** {best_threshold_num} &nbsp;&nbsp; **G-Mean:** {gmeans_num} &nbsp;&nbsp; **Model Accuracy:** {accuracy_num}%\n",
    "\n",
    "                    Precision   Recall      F1-Score    Support\n",
    "\n",
    "    0               {df_report.iloc[0,0]}        {df_report.iloc[0,1]}        {df_report.iloc[0,2]}        {df_report.iloc[0,3]}\n",
    "    1               {df_report.iloc[1,0]}        {df_report.iloc[1,1]}        {df_report.iloc[1,2]}        {df_report.iloc[1,3]}\n",
    "\n",
    "    Accuracy                                {df_report.iloc[2,2]}        {df_report.iloc[3,3]}\n",
    "    Macro Avg       {df_report.iloc[3,0]}        {df_report.iloc[3,1]}        {df_report.iloc[3,2]}        {df_report.iloc[3,3]}\n",
    "    Weighted Avg    {df_report.iloc[4,0]}        {df_report.iloc[4,1]}        {df_report.iloc[4,2]}        {df_report.iloc[3,3]}\n",
    "\"\"\"\n",
    "    \n",
    "    #yaml output dictionary \n",
    "    report_dict = {\n",
    "    \"model_fullname\": model_fullname,\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"best_threshold_num\": best_threshold_num,\n",
    "    \"gmeans_num\": gmeans_num,\n",
    "    \"accuracy_num\": accuracy_num,\n",
    "    \"classification_report\": df_report.to_dict(orient=\"index\")\n",
    "    }\n",
    "\n",
    "    with open(f'{model_name}_accuracy.md','w') as markdown_file:\n",
    "        markdown_file.write(markdown_content)\n",
    "\n",
    "    with open(f'{model_name}_accuracy.yaml', \"w\") as f:\n",
    "        yaml.dump(report_dict, f, default_flow_style=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training Models with Various Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: CV LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable - total 2 targets 0/1\n",
    "target_names = ['0','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Data into X and Y.\n",
      "Splitted Data into Train and Test.\n",
      "Vectorized Training Data.\n",
      "Oversampling Done for Training Data.\n",
      "Vectorized Testing Data.\n",
      "Model Fitted Successfully.\n",
      "\n",
      "\u001b[1mROC-AUC Score\u001b[0m \t\t: 92.0 %\n",
      "\u001b[1mBest Threshold\u001b[0m \t\t: 0.121 \n",
      "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.868\n",
      "\u001b[1mModel Accuracy\u001b[0m \t\t: 93.88 %\n",
      "\u001b[1m\n",
      "Classification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3395\n",
      "           1       0.44      0.75      0.55       181\n",
      "\n",
      "    accuracy                           0.94      3576\n",
      "   macro avg       0.71      0.85      0.76      3576\n",
      "weighted avg       0.96      0.94      0.95      3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model name variables\n",
    "model_fullname = \"CV Logistic Regression (LR)\"\n",
    "model_name = \"CV-LogisticRegression\"\n",
    "\n",
    "#cvlr model training\n",
    "cv = CountVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model, x_test_init, y_test, y_pred, gmeans_num, accuracy_num, roc_auc, best_threshold_num = train_model(\n",
    "    df=df, \n",
    "    input='text', \n",
    "    target='fraudulent', \n",
    "    test_size=0.2,\n",
    "    over_sample=True, \n",
    "    vectorizer=cv, \n",
    "    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch classification report and generate markdown report\n",
    "report = classification_report(y_test, y_pred, target_names = target_names, output_dict = True)\n",
    "report_generator(report, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\output\\jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([x_test_init, y_test,  pd\u001b[38;5;241m.\u001b[39mSeries(y_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m),index\u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39mindex)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m output\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed Text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFraudulent_Truth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFraudulent_Prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../output/jobs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fang\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fang\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Fang\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\Fang\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fang\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\output\\jobs'"
     ]
    }
   ],
   "source": [
    "#generate output csv\n",
    "output = pd.concat([x_test_init, y_test,  pd.Series(y_pred.astype(int),index=y_test.index)], axis=1)\n",
    "output.columns = [\"Processed Text\",\"Fraudulent_Truth\",\"Fraudulent_Prediction\"]\n",
    "output.to_csv(f\"../output/jobs/{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: CV-RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Data into X and Y.\n",
      "Splitted Data into Train and Test.\n",
      "Vectorized Training Data.\n",
      "Oversampling Done for Training Data.\n",
      "Vectorized Testing Data.\n",
      "Model Fitted Successfully.\n",
      "\n",
      "\u001b[1mROC-AUC Score\u001b[0m \t\t: 98.0 %\n",
      "\u001b[1mBest Threshold\u001b[0m \t\t: 0.130 \n",
      "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.920\n",
      "\u001b[1mModel Accuracy\u001b[0m \t\t: 97.65 %\n",
      "\u001b[1m\n",
      "Classification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3395\n",
      "           1       0.95      0.56      0.71       181\n",
      "\n",
      "    accuracy                           0.98      3576\n",
      "   macro avg       0.97      0.78      0.85      3576\n",
      "weighted avg       0.98      0.98      0.97      3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model name\n",
    "model_fullname = \"CV Random Forest Classifier (RFC)\"\n",
    "model_name = \"CV-RandomForestClassifier\"\n",
    "\n",
    "#model training\n",
    "cv = CountVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "rfc = RandomForestClassifier(n_jobs=3, oob_score=True, n_estimators=100, criterion=\"gini\")\n",
    "\n",
    "model, x_test_init, y_test, y_pred, gmeans_num, accuracy_num, roc_auc, best_threshold_num  = train_model(\n",
    "    df=df, \n",
    "    input='text', \n",
    "    target='fraudulent', \n",
    "    test_size=0.2,\n",
    "    over_sample=True, \n",
    "    vectorizer=cv, \n",
    "    model=rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch classification report and generate markdown report\n",
    "report = classification_report(y_test, y_pred, target_names = target_names, output_dict = True)\n",
    "report_generator(report, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate output\n",
    "output = pd.concat([x_test_init, y_test,  pd.Series(y_pred.astype(int),index=y_test.index)], axis=1)\n",
    "output.columns = [\"Processed Text\",\"Fraudulent_Truth\",\"Fraudulent_Prediction\"]\n",
    "output.to_csv(f\"../output/jobs/{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: TFIDF-LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Data into X and Y.\n",
      "Splitted Data into Train and Test.\n",
      "Vectorized Training Data.\n",
      "Oversampling Done for Training Data.\n",
      "Vectorized Testing Data.\n",
      "Model Fitted Successfully.\n",
      "\n",
      "\u001b[1mROC-AUC Score\u001b[0m \t\t: 94.0 %\n",
      "\u001b[1mBest Threshold\u001b[0m \t\t: 0.417 \n",
      "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.871\n",
      "\u001b[1mModel Accuracy\u001b[0m \t\t: 92.59 %\n",
      "\u001b[1m\n",
      "Classification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3395\n",
      "           1       0.39      0.80      0.52       181\n",
      "\n",
      "    accuracy                           0.93      3576\n",
      "   macro avg       0.69      0.86      0.74      3576\n",
      "weighted avg       0.96      0.93      0.94      3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model name\n",
    "model_fullname = \"TFIDF Logistic Regression (LR)\"\n",
    "model_name = \"TFIDF-LogisticRegression\"\n",
    "\n",
    "#model training\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc, x_test_init, y_test, y_pred, gmeans_num, accuracy_num, roc_auc, best_threshold_num = train_model(\n",
    "    df=df, \n",
    "    input='text', \n",
    "    target='fraudulent', \n",
    "    test_size=0.2,\n",
    "    over_sample=True, \n",
    "    vectorizer=tfidf, \n",
    "    model=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch classification report and generate markdown report\n",
    "report = classification_report(y_test, y_pred, target_names = target_names, output_dict = True)\n",
    "report_generator(report, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate output csv\n",
    "output = pd.concat([x_test_init, y_test,  pd.Series(y_pred.astype(int),index=y_test.index)], axis=1)\n",
    "output.columns = [\"Processed Text\",\"Fraudulent_Truth\",\"Fraudulent_Prediction\"]\n",
    "output.to_csv(f\"../output/jobs/{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4: TFIDF SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Data into X and Y.\n",
      "Splitted Data into Train and Test.\n",
      "Vectorized Training Data.\n",
      "Oversampling Done for Training Data.\n",
      "Vectorized Testing Data.\n",
      "Model Fitted Successfully.\n",
      "\n",
      "\u001b[1mROC-AUC Score\u001b[0m \t\t: 97.0 %\n",
      "\u001b[1mBest Threshold\u001b[0m \t\t: 0.001 \n",
      "\u001b[1mG-Mean\u001b[0m \t\t\t: 0.926\n",
      "\u001b[1mModel Accuracy\u001b[0m \t\t: 98.27 %\n",
      "\u001b[1m\n",
      "Classification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3395\n",
      "           1       1.00      0.66      0.79       181\n",
      "\n",
      "    accuracy                           0.98      3576\n",
      "   macro avg       0.99      0.83      0.89      3576\n",
      "weighted avg       0.98      0.98      0.98      3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model name\n",
    "model_fullname = \"TFIDF Support Vector Classifier (SVC)\"\n",
    "model_name = \"TFIDF-SVC\"\n",
    "\n",
    "#model training\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features = 500)\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "model, x_test_init, y_test, y_pred, gmeans_num, accuracy_num, roc_auc, best_threshold_num = train_model(\n",
    "    df=df, \n",
    "    input='text', \n",
    "    target='fraudulent', \n",
    "    test_size=0.2,\n",
    "    over_sample=True, \n",
    "    vectorizer=tfidf, \n",
    "    model=svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch classification report and generate markdown report\n",
    "report = classification_report(y_test, y_pred, target_names = target_names, output_dict = True)\n",
    "report_generator(report, model_fullname, model_name, gmeans_num, accuracy_num, roc_auc, best_threshold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([x_test_init, y_test,  pd.Series(y_pred.astype(int),index=y_test.index)], axis=1)\n",
    "output.columns = [\"Processed Text\",\"Fraudulent_Truth\",\"Fraudulent_Prediction\"]\n",
    "output.to_csv(f\"../output/jobs/{model_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "41cafc31f28d2400a8339ec2e2ac9e00a6cc1491edb64b84f92a333f1f8f2061"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
